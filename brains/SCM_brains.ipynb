{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f042f017-1827-4760-8314-0aec855fbe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lz4\n",
    "import nibabel\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.nn import pyro_method, DenseNN\n",
    "from pyro.distributions.conditional import ConditionalTransformModule\n",
    "from pyro.distributions import RelaxedBernoulliStraightThrough\n",
    "import sys\n",
    "sys.path.insert(0,\"./data/\")\n",
    "import torch\n",
    "from loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109db419-2233-4102-ac35-1d90ce9e8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if (type(m) == nn.Conv3d or\n",
    "        type(m) == nn.ConvTranspose2d or\n",
    "        type(m) == nn.Conv2d\n",
    "       or type(m)== nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight,mode='fan_in',a=.01,nonlinearity=\"leaky_relu\")\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41781f34-547c-42a9-9eb6-0581541270c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(x,x1,x2,y1,y2,z1,z2):\n",
    "    return x[x1:x2,y1:y2,z1:z2]\n",
    "def downsample(x,factorx,factory=None,factorz=None):\n",
    "    if factory==None:\n",
    "        factory=factorx\n",
    "    if factorz==None:\n",
    "        factorz=factorx\n",
    "    return x[::factorx,::factory,::factorz]\n",
    "def brain_slice(x,slice_num):\n",
    "    return x[:,:,slice_num]\n",
    "def normalize(x,norm_type=None):\n",
    "    x-=np.min(x,keepdims=True)\n",
    "    x/=(np.max(x,keepdims=True)+.00001)\n",
    "    return x\n",
    "    \n",
    "def load_one_brain(path):\n",
    "    img=nibabel.load(path)\n",
    "    img=img.get_fdata()\n",
    "    \n",
    "    print(img.shape)\n",
    "    img=crop(img,50,178,50,178,12,140)\n",
    "    print(img.shape)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "618c2512-feb7-410b-b8d2-a8ba0671849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_slice(volume,slice_num):\n",
    "    plt.imshow(volume[slice_num,:,:],cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21ccfa76-eda6-4aa4-82c5-95f54ffbbeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 240, 155)\n",
      "(128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "basic_brain=load_one_brain(\"/usr/local/faststorage/BraTS19_Data/Training/Data/BraTS19_2013_3_1/BraTS19_2013_3_1_flair.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14615c8a-2387-4687-8c52-2ef3ff5bc983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlfElEQVR4nO2de4xd1ZXmvxUDgWDjB37iBwXCmIBEgFSACAu5yaTD9LQaKYpQp1HEjIicP8iIVnrUwIyUdEczKChRpyMySWQN6baiTBP6wYBQ0t20A2ryIi4INGDHj3b8xHaB41cC4eGs+ePeOnxnUXv5lOvWrbLP95Ms73v3ufusc+7dddbaa+21zN0hhDj1eddkCyCE6A+a7EK0BE12IVqCJrsQLUGTXYiWoMkuREsY12Q3sxvNbJOZbTWzu3ollBCi99iJ+tnNbBqAzQA+DGA3gPUAPu7uG3onnhCiV5w2js9eDWCru28DADN7AMBNAIqTfe7cuT4wMDCOUwohMrZv345XXnnFRusbz2RfDGAXvd4N4JrsAwMDAxgaGhrHKYUQGYODg8W+CV+gM7PVZjZkZkMvv/zyRJ9OCFFgPJN9D4Cl9HpJ970a7r7G3QfdfXDevHnjOJ0QYjyMZ7KvB7DczC4wszMA/CGAR3ojlhCi15ywze7ub5nZpwH8E4BpAL7p7i/2TDIhRE8ZzwId3P27AL7bI1mEEBOIIuiEaAma7EK0BE12IVqCJrsQLUGTXYiWoMkuREvQZBeiJWiyC9ESNNmFaAma7EK0hHGFy4pTkwMHDlRts7fzIJx99tm14zZu3Fi1169fX+vjDEhnnXVW1f7kJz9ZO27FihVV+5pr6ukQ7rvvvqp95plnNpJdlNGTXYiWoMkuREuQGn8Kc+zYsaq9ZcuWWt+nPvWpqr13795a3/z586v2woULq/aRI0dqx/3mN7+p2uecc06tb8OGt1MRvvXWW1WbVXoAmD17dtX+/ve/X+u7/PLLq/Zll11Wtb/xjW/UjluwYAHE8dGTXYiWoMkuREvQZBeiJchmP8XYtevt7N6f/exnq/Z3v1tPKHT66adXbbabAWDWrFlV+13vevt5cNpp9Z8Lu+KiW45ddtOnTy/Ky+sDbNsD9TWCzZs3V+2rr766dtzrr79etT/96U/X+j7zmc9U7fe85z1FOdqAnuxCtARNdiFagtT4k5x9+/bVXn/pS1+q2qz6smoO1NXud7/73bW+GTNmVG1W41n1B4A33nijakcVfNq0aaOOx+5AADh69Oion4ljzpkzp2q/+uqrteNYxq997Wu1vs9//vNV+/7776/aN998c+24eA9ORfRkF6IlaLIL0RI02YVoCbLZT3Ki/fqrX/1q1L4YUsrhrey6Aur2PNvN0fX22muvVe3f/va3tT4+ll1ebOcDdZud3XUA8Oabb1ZtrhO4f//+2nEzZ85ECb4Hd999d9V+8MEHa8c99NBDo8p+KnHcJ7uZfdPMhs3sBXpvjpk9ZmZbuv/PzsYQQkw+TdT4vwZwY3jvLgDr3H05gHXd10KIKcxx9RV3/1czGwhv3wRgVbe9FsATAO7spWCiTElVB4DDhw9XbVafY5TcGWecUbWj2sqJIlhVj64xdqPFPn7NLrsYxcZqfNw5xwkwFi9eXLXjDj6+Nv4M8M6deiO8/PLLtderVq2q2t/73vdqfew6PJk50QW6Be4+si9yHwDtMRRiijPu1Xjv/Cn1Ur+ZrTazITMbin9NhRD940SXHfeb2SJ332tmiwAMlw509zUA1gDA4OBg8Y+CKBNXujlqbufOnbU+Vsl5BTuqt7wqHtVUXhXnlfq4ks6mQIygY9Wdzx1NBu7jSDigHtU2d+7cqh0TYLD6H+XgMbiPE28A9RX+gYGBWt+OHTuqdrapZ6pzok/2RwDc2m3fCuDh3ogjhJgomrje/gbAjwGsMLPdZnYbgC8A+LCZbQHwH7qvhRBTmCar8R8vdH2ox7IIISaQUzNU6BQj2pfsXtu6dWutj91mbDe/8sortePYdo42MNPUZo99JVs5c/PFtQleS2AXWnQjsozR7ud7wO24y43PHeX4yEc+UrWfeOKJ4vhTHcXGC9ESNNmFaAlS408CeEMIUFeL46YQVivZhRZdUqyCx9JK7A7jaL2YeII3zHCkXZQje5/V+jg+u7l+/etfV+0YacfxGzFCj6+TVfd4zSxHNDX43v34xz+u9V1//fU4WdCTXYiWoMkuREvQZBeiJchmPwmIriBOHsk2NVC379klFRND8Os4fomYG75kDwPv3AU3QrSVWcYoB9vmbLPzeePnohy8RsDjRbs8c8vx63vuuafWd91111Xt0jVPFfRkF6IlaLIL0RKkxp8ERPWQc65xNB1QdxOxOyxGlvGY0S3HsCsrqvFNo8fYlRc/k8nB5+Yxsp1t0VwpqedxF2CWR5/hHXAAcN9991XtO+64oyjHVEBPdiFagia7EC1BavwUhdXMqMbzSnJUaUsJGjI1PkausQratFJrtpmGV8uza4mRgiUZY+prjrSL6nlJnY7vczXZzDsR78HatWurNlfQvffee2vHTYX01HqyC9ESNNmFaAma7EK0hMk3JMSosN0Y7Uu2y6OtzK44ttOjzc42ZLRz+VgeP7rNWK5sFxnb25lrLO6cYxue7feYK58j6mKiD5aDzx2vhRNlcC77OGbcccfjv/TSS1X7c5/7XO24j370o1X7/e9/PyYDPdmFaAma7EK0BKnxUxRWrbNorJjznTfGsAoe3WtRrWdKOd+zBBUx6qwkc+Z6yyLy2KyJbiweM8uTx9cSN9PwfYz3il/H+11yD8YSVV/96ler9l131UsjrlixAv1AT3YhWoImuxAtQZNdiJYgm32KktnsbB9H1xvbovy5aMtyX1Zume3Q6PJid1tM9MjuQb6WLJw1CyllOaK9nYXc8nXzdcU1C5Y33g++tnidpTBeTrYRZXzyySdrfRdeeGHVnsg89E3KPy01s8fNbIOZvWhmd3Tfn2Nmj5nZlu7/s483lhBi8miixr8F4E/c/VIA1wK43cwuBXAXgHXuvhzAuu5rIcQUpUmtt70A9nbbR81sI4DFAG4CsKp72FoATwC4c0KkbCGZuy1zVzXNG8+urGwMVrujasrqblTPefzYx7CMUT1nVZvV8yxaLytDVRobqN+fzGyK52bThseM52UZDx06VOt7+umnq/a11147qry9YEwLdGY2AOBKAE8BWND9QwAA+wAs6K1oQohe0niym9l0AH8P4I/d/Qj3eedP96h/vs1stZkNmdkQV+4QQvSXRpPdzE5HZ6J/293/ofv2fjNb1O1fBGB4tM+6+xp3H3T3wXnz5vVCZiHECXBcm906Bsz9ADa6+19Q1yMAbgXwhe7/D0+IhC0ls9nZLuUsLUAeBstkrj1+nYWYZokem9LU9Zbt9OPPZTvisrUDHj/L6hNdb6Wknln4cCyf/aMf/ahqX3XVVaPK3gua+NmvA/AJAM+b2bPd9/47OpP8QTO7DcAOADf3VDIhRE9pshr/AwClP9sf6q04QoiJQhF0U5RMHWc1PqqLJZdXVLOz5Bil46IKy8kX4xgsP8sRkzmyS61pX1O3JFBW4zOVPsttH1XrUiRi/P440i4uVHMdAN61OGfOnKKMJ4Ji44VoCZrsQrQEqfFTlKaqb1Y5tGnkWlSL+XOsfsaVf1bjY4ReSdXOriUmjeA+Hi+qyFl5qZLqHiPtmBglV5JpNFlK8Lljnjwec8OGDVV75cqVjcZuip7sQrQETXYhWoImuxAtQTb7FIVt4OiqYbs3ut7YNcR2aXQZZfY82858riyCLquPVhobKNvlQF1+tqMzmz3bOcf3NCtTnSWQiDZ7aS0h3t/M7ce7CZ955pmqPTg4WDsuW0togp7sQrQETXYhWoLU+CkKq6Nx4weroFG1K6mgUd3PItdK5Zqiu4rHyCLLMhW/VCYKKJsamYocr7+kWmcus+jOZPmzXH5ZshC+tnjugwcPjnpcTHKxcOHCosxN0JNdiJagyS5ES9BkF6IlyGY/CZg/f37tNSdoiPYl26zcF217tkOjrcx9PEas9TZr1qyqneVy53zqET53DCPlc5fy0I927tIYfK7oQmuasz5bVygl/QDydQu22XlN4LnnnqsdJ5tdCNEITXYhWoLU+JMQTiIRVTtW41m9jaoumwLRncSqb+Z6Y6KZ0DT3G7sE4/isWrOKH1Vuvh/xXOzmytRxliOOwSp/5vbj+xbV9iyPPr9mc2XHjh2147KIyCboyS5ES9BkF6IlSI0/yZk7d27tNaujM2bMqNpRzeZcZ1lUGPdF9ZNV4Ux9zlIss3obI8tKKniW6jmq56UIvahm83GxL6vwymTmSpaMpOQZ2bt3b+04XrVfsGDsBZj0ZBeiJWiyC9ESNNmFaAmy2SeYzI6LUVz33HNP1V62bFnV/sQnPlE7jt1rcXcV75BjOzTa7L/85S+rdoxwYxsyi1zLItLYNmcbOyaoyMpP87Gl0stA3S0Xbeoo12gyRbLy1tHtVxqnaXKQCK+RDA/XyyfydzYhNruZnWlmPzWz58zsRTP78+77F5jZU2a21cy+Y2a9LUwlhOgpTdT41wHc4O7vA3AFgBvN7FoA9wL4srtfBOAggNsmTEohxLhpUuvNAYz4aU7v/nMANwD4o+77awH8GYCv917Ek5tYsZN5/vnna69ffPHFqr1ly5aq/a1vfat23C233FK1L7744lofq7uzZ8+u2jHiatu2bVU7UytZpY0qOPfFTSxsTpTccFGurPIpHxfVbHYjsrsRqF8bq/hR3efjmm6KiTJm5bb4fNkmGR4/VqTlXITvfe97izKWaFqffVq3guswgMcA/DuAQ+4+ctd3A1g85rMLIfpGo8nu7sfc/QoASwBcDeCSpicws9VmNmRmQzFLqhCif4zJ9ebuhwA8DuCDAGaZ2Yi+swTAnsJn1rj7oLsPzps3bzyyCiHGwXFtdjObB+BNdz9kZmcB+DA6i3OPA/gYgAcA3Arg4YkU9GSC3ScHDhyo9XESwc2bN9f62K7jxBBsywP1MMpYf43HZ1dWtDXZ3cY2b4Q/d8455xT7on3JcrGdHm1ltsWzOm3cF8N7WX6uPxdl5DWBmIiD1wGyHPvxPvKxWUhvSaYI35/oEuXfywc+8IFaX0xKOhpN/OyLAKw1s2noaAIPuvujZrYBwANm9j8B/AzA/Q3GEkJMEk1W4/8NwJWjvL8NHftdCHESoAi6CYBdN0uXLq31cVTU9u3ba30lt9miRYtqxx0+fLhq79y5s9Z35MiRUceLKiG/jmOwSsuqe1TjsxLI+/btq9qcXCKq2aU8c/F1tmuMj8vy6WVlnTIVnMeI5+bIxCwvPb/OkoDw+FwWCqjf07gj7sILLyyOWclw3COEEKcEmuxCtASp8RMAq2yswgLAueeeW7VZLQPqK9h8HLeBelReVAlZxWcVOa6Wc8RbzHXG0V9ZeSZ+Hc0ElmvOnDkowap1HKOUHGMsm0xKZaiyCLoYDZidu2RexONiRF0JHuPo0aO1PvbsxO+zCXqyC9ESNNmFaAma7EK0BNnsEwDbUzF5wtatW6t2dGVx8kjevRXLP3HEWLQN2d5kOaL9x24dTooA1O30zF5luzxG4fGY7J6K7q+sHHJTezgrZcXrJ3xd0Wbnc8e1g6Y2e5aXPrPZS/LHc7GLMbrlsnWMEfRkF6IlaLIL0RKkxveAbKNKjBjjnX9Rjec+3mCRRdBFdbGULCOqkaz2RRlZLs51FjeIsOobI8vY5chqfDyOx4gRdKXEENmmnjg+H1vKzxfPnanEWTXWLJKviZodiSZgtnlpxGTL5NOTXYiWoMkuREvQZBeiJchmHwNskz3zzDNVO9pj7ELbv39/rY9dapnrjW2+mCOcw2pjqq9sFxnDLqkYjnveeedVbV5HiAkhOQFEdKnxdfKaQAxFzXLKl5I0Zskf4m6zUsLMsZQ8zuxtPl/mHmT7O64XlHbVRZud73d0lzYJx9WTXYiWoMkuREuQGp8Qdxaxu2NgYKBqc453ANi0aVPVjjniWDWLJZlKamBUn9mtFXPcsXqalUPmMc8///xa35IlS6r2zJkzR5U9yhivk02ULPcbE1XRUpmrzDyJkXElFTne+yxXPF9nHJ9l5L6sLHP8Lko7C+NxpR18gFxvQghCk12IliA1PsCq++23317r4wgmXmHmVXSgnqwhbqrIcpE1jX7LqriyelraBALUTYHYx9eWpYHmc0U1nl+z/JlqGlf0Wf3P1PgoF1Pa1BNX4/m4LJIvylgqbZWtjsd7wPJn95uJv7mR31LqOSj2CCFOKTTZhWgJmuxCtITW2+wxEumLX/xi1Y72Ntt1bJNFdxKXYIp2OY8R+3iczHbLbDm2Rfm4GHXG9na02UvJF6O9yiWqYvmh0rkzmze7Lr6nWe72zFYuJdKMcozlc9zX1E7Pkl2W7Pd4XCxN3YTGT/Zu2eafmdmj3dcXmNlTZrbVzL5jZs3jD4UQfWcsavwdADbS63sBfNndLwJwEMBtvRRMCNFbGqnxZrYEwH8C8L8AfMY6+soNAP6oe8haAH8G4OsTIGNP+MUvflG1d+/eXbV/+MMf1o6LudoYVrEydZzJ3DhRneMItWzTBrtXYiRYSY2P0W+sdkcVn+9BKfkDUHevZSp4ST4gL5nE5+aEHVmijMy1x668eD+YzAXYNDIuq1abRrk1rP4aE45kn6uOOe4RHf4SwJ8CGJHyXACH3H3kl7wbwOKGYwkhJoHjTnYz+30Aw+7+9ImcwMxWm9mQmQ3F7ZhCiP7R5Ml+HYA/MLPtAB5AR33/CoBZZjaiyy4BsGe0D7v7GncfdPdB3hsthOgvTeqz3w3gbgAws1UA/pu732JmfwvgY+j8AbgVwMMTJ+bYYVcNADz55JNVm2usHTx4sHYc29/R7iqFQ0Z7iW2+JrbUaMeyLRvtfj4u2pelc0e7PJOxacIHtuGjjHy+LNyUPxfdWuz241DiGCrKNnvmpmTbO+Zdz2RkNxevHQC5W5Hh68zy47O80ZXH8jddI2HGE1RzJzqLdVvRseHvH8dYQogJZkxBNe7+BIAnuu1tAK7uvUhCiIngpIigY1WJI97YnQbUSw9v37691sdqFLvesnM1jbKKKlVWZihLhMBqG8sbXTVZlFVTUyNzebHayqp7dPNlEWOl8eNnSqYLUE8WwtGM8XspJZCIMme7BVmOaK5wIo5o9mUJMUrEiMtSFF6Ug12dWbKNEoqNF6IlaLIL0RKmjBrPalX0x+/Z87ZXj0srRbVveHi4OAav7HJfTLrAZKvxTFSpsmgpNhOydMaszo0ldXJT+N5F+TnvHKu+mbzxuygldciSK8QVcjbZeAU+Ro9lZlNT04jHyK4zM9my7z2rNFvaaBPPlSUcURVXIUSFJrsQLUGTXYiWMGk2e7TPuJxSdKnxsZwQMrpPeLdW3L3Gbhze8TSWUrpN3VqlXOXxfJk9n5U7ymxPfs12XbbTKosYyyK6SueN587ynXNfjE7j752TeLLtGs+VuaSyksqlNQagvt6TJarkMTN3aVYumttRDl6riLv2Ru6jEk4KITTZhWgLfVXj3b1SU37wgx/U+tatW1e14yaW0maGmCOOVaesdFOm6pXygQHlSKeobvFGh0ytipFULD+Pn5VditfJaiDfq1iplcfMyimV5IuvM/W8ZJ5Esk0m7A6M5bDYDInfLV9nds2Ze5C/z2jylKrmxvEzV2dJ/c/cmaUoPKnxQghNdiHagia7EC2hrzb7sWPHql1D7GoDgF27dlXtaIeyjcNul8zuin3sPuF859GdlOUBL9np8Ti28bIx4poD239sG0Y3Eb/mtQigft18rxYtWlQ8bv/+/bU+vleZ+y5z5/E9iNfJ8DXHNRJeZ+AdZdFmL7n5gDwJCJMl+mia2z4LiWU5ol1dGjNz0fF3BLztEpTNLoTQZBeiLfRVjX/jjTeqBBOZ2yxGSLH6wu6TuPuJ1f+s3BF/LqpQrOJz1FYcM3OzZHnkWSWMqhjndMt2vfG9imOUEjlkavyBAwdqffzdNI34iyonj8EyZnnVYl56/h3wcTGKrbSzLb7m3050oTUt2RzhMTMXY+meZsTfN0c2ZiZUCT3ZhWgJmuxCtIS+qvHTpk2rIqGyDfxRjedNLawOxTz0vHEiqko8JkdjRXOC1d0VK1bU+jhqiVMbc2pqoK62xui3LMEBq/isss2ePbsoR1Tj2Vzha4lVP9nUyCK6+LhshTlGEfJ9ZXmzskgxyo9V9yxKLovk49esnmcbWuJvJzNlSptrourPv4Om+QDj/bjsssuqdqnsV1pJttgjhDil0GQXoiVosgvREvqevGLEZou2LNsq0QXDu+D4c1n532i7sBuD3WsxMeWyZcuq9iWXXFLrY/t4586dVTu6rvi4mKSD5ch2ULGdHtcmOHd5jH7jHOcXX3zxqO8D9cg7XsMA6usRfL8zezXa4qXdg1mprCyZI9M0X32UmdcfsgQYcYzsHpTcbVlCk2yNhPuWLFlSO+7888+v2vEejNjwWQLSpvXZtwM4CuAYgLfcfdDM5gD4DoABANsB3OzuB0tjCCEml7Go8b/j7le4+2D39V0A1rn7cgDruq+FEFOU8ajxNwFY1W2vRacG3J3ZB1577TW88MILAIAjR47U+jIViMk292cbIkp50KI7af78+VV7wYIF75B/tHZUP1l1j2ZCtvGDZeToPVbfgLopEE0I/hyrgVkpq2gmcBmtLPKraVKKTFXn101zrTdNlAHkKjiTJS3h7zpzyzW9H/G3yZ9jlxqbYUDdFcemFn+uF643B/DPZva0ma3uvrfA3UcqNuwDsGD0jwohpgJNn+wr3X2Pmc0H8JiZ/Zw73d3NbNQ/Zd0/DquBdz5BhBD9o9GT3d33dP8fBvAQOqWa95vZIgDo/j9c+Owadx9098G4IiyE6B/HfbKb2dkA3uXuR7vt3wXweQCPALgVwBe6/z98vLFeffVVrF+/HsA7ky5kdlepjG3cndTUfcJ2bnQB8phx9xrbSVyHLOaoz3J/N80Hn9V3yxJbsBuNNal4r9gu5TpqQH4fmcyVxded1S/j42Locqkv2t5ZCHIpcUYW+htduuxKje7S0vcZf1csV5ZAlO3ypUuX1o5juaJLt1eutwUAHupOuNMA/F93/0czWw/gQTO7DcAOADc3GEsIMUkcd7K7+zYA7xvl/QMAPjQRQgkhek/fk1e89NJLAN6pXrGql0XXMVFl411SUU1jlZPV8bh7iBNgRPV8+/btVZsj6KJJwsTxmSh/aVddVCv5fDF/eNN7xfcnc4M2zSkfKbkYoxqfqbesMvP3F2Xi47KkEfwbyxKMRBn52CxSsJQoI8oV5ecx2PUbdzsy8TsbuTbtehNCaLIL0RY02YVoCX212c8880xcdNFFAIA9e/bU+thuie6NUuLB6O5h2zZmcOHXvGuMbSSgbg9H98bmzZurNmenKdlPsQ3kYZ8sY2nnWSTaniW3WVzDYFt27969tb5SmGqW7zxzl2Yhzmy/xj5ej8hyz5ds+zh+05z9TZNWRplLO+xiX1xX4Xu3ePHiqh0TTjIxO5Iy1QghKjTZhWgJfVXjp0+fjpUrVwIAfvKTn9T6OCItqnPsvirtDAPqKngs+1xSt6IqzbvURtyEIwwPvx0RzKZAdH8x0SThY+O5S+7BaJJw2HFUK9nMyXb38ef4WiJZosQsWisrd8RkKj7fD74HWXmmpskl4vdSOu/x+kq79rIddrGPIxiXL19elJHvwYg5PBb0ZBeiJWiyC9ES+qrGn3XWWbj88ssB1NV2ANi4cWPVjmoxbw5gtSxW8+TV86zaZraZhjfJ8Op7lJlVqqiWNVVhIyV1NKrLWSVb/hyr57EyLvcdPny41lfyGGQltbKkDlne9UyNL63Gx5V0Nu2yHHTZ5qKS9yC+zjYUsYofv7MskpI3vHCu//gbZhPzggsuKI5XQk92IVqCJrsQLUGTXYiW0Pdab9OnTwfwzoQJI+8D77SL+Fi2u6JtX9rhBJQTYERXCrvXYjJHduexTXaiO8Oa5j+Pthu7ZDjiCqivJXCUYoy44h190U3J9y6LoMsST5Ryysd7la1v8Jj8ubj+kO16K+2qi/eeZcwSQsbr5HPz7zH+/thmj7sY2d3G8yDa/fzblM0uhCiiyS5ES5i08k9RDdm2bVvVjqoSq6CsYsUNKKyOxqgzVuFKbaDuhopjsFysimUbVaLKxqpZVDkztb40xsKFC2t9HEXIZsjPf15LCFwjRtCxay+LCmM54qYhvies6mYbSSJ8bNMovCzxSVauiseI5cf4c/G3WTIr4yYWVuNZVQfqcyHLo8+u3yhjE/RkF6IlaLIL0RI02YVoCX232UdsrxkzZtTeP++886p2dHmxC4ntmOh6Y5dMtLdLdl1MKsn2VHTxlBItZOV5szzp2c4otnOjLV+qOQfU7Tp21WzdurV2HNt88TqZLMS0JBNQrrEWvxe+H9l1ZnX8+LuINnspnDULiY2hrdkuuKa/Cf4+M3ubrzne+2uuuab4uSboyS5ES9BkF6Il9F2NH1HBomuC1fjnn3++1lfKx5aV2Ik7uUo73TKXUVRvS+6faJKw+ytGUmVJGHh8dn9F9x27GKNKyyon34OmZZyA5i6vbCdaKfdbVOOzyDUek+9VVJFZ3ngtJddblIPHj/naMzW+pP7H/Ih8bfE3wao7yxXnSIw6HSuNnuxmNsvM/s7Mfm5mG83sg2Y2x8weM7Mt3f/LGe2FEJNOUzX+KwD+0d0vQacU1EYAdwFY5+7LAazrvhZCTFGaVHGdCeB6AP8ZANz9DQBvmNlNAFZ1D1sL4AkAdzY9cYza4o35u3btqvXxCnO2KYGTWWSr7KyWRTWe1a3YVyovFVU2vraogjctrcSrt1Ht4/uRqZgxwrAkR1bJlolmR1aGiuF7muVwi/eqVBU1Ji1hebONNkyUg4+L5hv/zjLvCq+yxxV3VvGzvIQsRyxx3jTCskSTJ/sFAF4G8Fdm9jMz+z/d0s0L3H0k4fg+dKq9CiGmKE0m+2kArgLwdXe/EsCvEVR27/w5GvVPqJmtNrMhMxvip7cQor80mey7Aex296e6r/8Oncm/38wWAUD3/+HRPuzua9x90N0H582b1wuZhRAnQJP67PvMbJeZrXD3TejUZN/Q/XcrgC90/3+4yQlH7LBo461fv75qb9q0qdbHGgHbPtG2Ylsu2qulxAXRjZOVNMrKKTFsy2aRVLGvZF/G97MS0ZntybDNGr8Ltjd5vSCzy6PdX7Ivs/WBuDZRirzL7lu02fl8cU2A4TFjMg++j3HHGtcuYBs72vb8uVjvgOUqlTrrBU397P8VwLfN7AwA2wD8F3S0ggfN7DYAOwDc3FPJhBA9pdFkd/dnAQyO0vWhnkojhJgwJi2CLqqinFyBc8hHZs6cWbWjWsmqXnS9sSrGEW9RJcxyf5dMAY7wA3K1knPgxz529bH8WbXXaE6w+sj3J6qVfJ1RDh6fVczoisxysvP5sgg3vo/RhcmfK8kUiXLwtWWfY+Jvp7SpB6h/n2z+xOvkvrh2xWr9smXLGsl4Iig2XoiWoMkuREvQZBeiJfTdZh+xg2PIYLYjie06tvWjfcY2anS9sf3N5442WJZ7vhSqO5YSv1xqN+7MY1sxc6/x/Yl2dFbOuTRGtOf53vE9iNfCfVm+9sxWZjky114WEpslaczy3pfkjWHY/NuJrjfO28/3J9r9/JuLNvuVV15ZtccbEpuhJ7sQLUGTXYiWYGMpKTzuk5m9jE4AzlwArxzn8IlmKsgASI6I5KgzVjnOd/dR49L7Otmrk5oNuftoQTqtkkFySI5+yiE1XoiWoMkuREuYrMm+ZpLOy0wFGQDJEZEcdXomx6TY7EKI/iM1XoiW0NfJbmY3mtkmM9tqZn3LRmtm3zSzYTN7gd7reypsM1tqZo+b2QYze9HM7pgMWczsTDP7qZk915Xjz7vvX2BmT3W/n+908xdMOGY2rZvf8NHJksPMtpvZ82b2rJkNdd+bjN/IhKVt79tkN7NpAP43gP8I4FIAHzezS/t0+r8GcGN4bzJSYb8F4E/c/VIA1wK4vXsP+i3L6wBucPf3AbgCwI1mdi2AewF82d0vAnAQwG0TLMcId6CTnnyEyZLjd9z9CnJ1TcZvZOLStrt7X/4B+CCAf6LXdwO4u4/nHwDwAr3eBGBRt70IwKZ+yUIyPAzgw5MpC4D3AHgGwDXoBG+cNtr3NYHnX9L9Ad8A4FEANklybAcwN7zX1+8FwEwAv0B3La3XcvRTjV8MgBPC7+6+N1lMaipsMxsAcCWApyZDlq7q/Cw6iUIfA/DvAA65+8guk359P38J4E8BjOxEOXeS5HAA/2xmT5vZ6u57/f5eJjRtuxbokKfCngjMbDqAvwfwx+5e257XL1nc/Zi7X4HOk/VqAJdM9DkjZvb7AIbd/el+n3sUVrr7VeiYmbeb2fXc2afvZVxp249HPyf7HgBL6fWS7nuTRaNU2L3GzE5HZ6J/293/YTJlAQB3PwTgcXTU5VlmNrJvtR/fz3UA/sDMtgN4AB1V/iuTIAfcfU/3/2EAD6HzB7Df38u40rYfj35O9vUAlndXWs8A8IcAHunj+SOPoJMCGxhDKuzxYJ3NyvcD2OjufzFZspjZPDOb1W2fhc66wUZ0Jv3H+iWHu9/t7kvcfQCd38P33f2WfsthZmeb2YyRNoDfBfAC+vy9uPs+ALvMbEX3rZG07b2RY6IXPsJCw+8B2IyOffg/+njevwGwF8Cb6Pz1vA0d23AdgC0A/gXAnD7IsRIdFezfADzb/fd7/ZYFwOUAftaV4wUAn+2+fyGAnwLYCuBvAby7j9/RKgCPToYc3fM91/334shvc5J+I1cAGOp+N/8PwOxeyaEIOiFaghbohGgJmuxCtARNdiFagia7EC1Bk12IlqDJLkRL0GQXoiVosgvREv4/y9ZRLSHRvncAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_slice(downsample(basic_brain,2),32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91350b36-2a7c-4398-bc9b-4e0ae4ff8638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim=512,k=4):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(1, k, kernel_size=3, stride=1)\n",
    "        self.conv2=nn.Conv2d(k, 4*k, kernel_size=4, stride=2,padding=2)\n",
    "        self.pass_conv_1=nn.Conv2d(4*k, 16, kernel_size=3, stride=1,padding=\"same\")\n",
    "        self.conv3=nn.Conv2d(4*k, 4*k, kernel_size=3, stride=2,padding=1)\n",
    "        self.pass_conv_2=nn.Conv2d(4*k, 16, kernel_size=3, stride=1,padding=\"same\")\n",
    "        self.conv4=nn.Conv2d(4*k, 8*k, kernel_size=3, stride=2,padding=1)\n",
    "        self.conv5=nn.Conv2d(8*k, 8*k, kernel_size=3, stride=2,padding=1)\n",
    "        #self.fc1=nn.Linear(6*k*8*8,64)\n",
    "        self.z_mean_fc=nn.Linear(4*4*8*k,z_dim)\n",
    "        self.z_std_fc=nn.Linear(4*4*8*k,z_dim)\n",
    "        self.lrelu=nn.LeakyReLU()\n",
    "        self.in1=nn.BatchNorm2d(k)\n",
    "        self.in2=nn.BatchNorm2d(4*k)\n",
    "        self.in3=nn.BatchNorm2d(4*k)\n",
    "        self.in4=nn.BatchNorm2d(8*k)\n",
    "        self.Sigmoid=nn.Sigmoid()\n",
    "    def forward(self, xs):\n",
    "        x=self.lrelu(self.in1(self.conv1(xs)))\n",
    "        \n",
    "        x=self.lrelu(self.in2(self.conv2(x)))\n",
    "        \n",
    "        p1=self.pass_conv_1(x)\n",
    "        x=self.lrelu(self.in3(self.conv3(x)))\n",
    "        p2=self.pass_conv_2(x)\n",
    "        x=self.lrelu(self.in4(self.conv4(x)))\n",
    "        x=self.lrelu(self.conv5(x))\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        z_loc=self.z_mean_fc(x)\n",
    "        z_scale=torch.exp(self.z_std_fc(x))\n",
    "        return z_loc,z_scale,self.Sigmoid(p1),self.Sigmoid(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf435e8f-66c1-4eb8-b26d-0eea2076c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim=256,k=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.deconv1=torch.nn.ConvTranspose2d(z_dim//4+1, 8*k, kernel_size=4, stride=2,padding=1)\n",
    "        self.deconv2=torch.nn.ConvTranspose2d(8*k, 4*k, kernel_size=4, stride=2,padding=1)\n",
    "        self.deconv3=torch.nn.ConvTranspose2d(4*k, 4*k, kernel_size=4, stride=2,padding=1)\n",
    "        self.deconv4=torch.nn.ConvTranspose2d(4*k, 2*k, kernel_size=4, stride=2,padding=1)\n",
    "        self.pass_conv1=torch.nn.Conv2d(2*k+16,2*k,kernel_size=3,stride=1,padding=\"same\")\n",
    "        self.deconv5=torch.nn.ConvTranspose2d(2*k, 2*k, kernel_size=4, stride=2,padding=1)\n",
    "        self.pass_conv2=torch.nn.Conv2d(2*k+16,2*k,kernel_size=3,stride=1,padding=\"same\")\n",
    "        self.deconv6=torch.nn.ConvTranspose2d(2*k, 2*k, kernel_size=4, stride=2,padding=1)\n",
    "        self.conv1=torch.nn.Conv2d(2*k,2,kernel_size=5,stride=1,padding=\"same\")\n",
    "        self.in1=nn.BatchNorm2d(8*k)\n",
    "        self.in2=nn.BatchNorm2d(4*k)\n",
    "        self.in3=nn.BatchNorm2d(4*k)\n",
    "        self.in4=nn.BatchNorm2d(2*k)\n",
    "        self.in5=nn.BatchNorm2d(2*k)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.lrelu=nn.LeakyReLU()\n",
    "\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.z_dim=z_dim\n",
    "    def forward(self, z):\n",
    "        z=z.view(-1,self.z_dim//4+1,2,2)\n",
    "        #print(z)\n",
    "        x = self.lrelu(self.in1(self.deconv1(z)))\n",
    "        x = self.lrelu(self.in2(self.deconv2(x)))\n",
    "        \n",
    "        x = self.lrelu(self.in3(self.deconv3(x)))\n",
    "        x = self.lrelu(self.in4(self.deconv4(x)))\n",
    "\n",
    "        #x =self.relu(self.pass_conv1(torch.cat([x,p1],1)))\n",
    "        \n",
    "        x = self.lrelu((self.deconv5(x)))\n",
    "\n",
    "        #x =self.relu(self.pass_conv2(torch.cat([x,p2],1)))\n",
    "        #x = self.lrelu(self.deconv6(x))\n",
    "        #print(x)\n",
    "        x=self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        recon_loc=x[:,0,...]\n",
    "        recon_var=torch.exp(x[:,1,...])\n",
    "        \n",
    "        \n",
    "        return recon_loc,recon_var\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b512bd02-129a-4096-9dac-b03c5108a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalAffineTransform(ConditionalTransformModule):\n",
    "    def __init__(self, context_nn, event_dim=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.event_dim = event_dim\n",
    "        self.context_nn = context_nn\n",
    "\n",
    "    def condition(self, context):\n",
    "        loc, log_scale = self.context_nn(context)\n",
    "        scale = torch.exp(log_scale)\n",
    "        ac = transforms.AffineTransform(loc, scale, event_dim=self.event_dim)\n",
    "        return ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9096f1ef-777d-49eb-bae2-9db11cf27a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=1,z_dim=64,k=4):\n",
    "        super().__init__()\n",
    "        fc_1=nn.Linear(input_size,4)\n",
    "        fc_z_mean=nn.Linear(4,1)\n",
    "        fc_z_std=nn.Linear(4,1)\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "    def forward(self,z,y):\n",
    "        x=self.relu(fc_1(y))\n",
    "        affine_1=fc_z_mean(x)\n",
    "        affine_2=fc_z_std(x)\n",
    "        return affine_1,affine_2\n",
    "class Estimator(nn.Module):\n",
    "    def __init__(self, input_size=512,z_dim=1,k=4):\n",
    "        super().__init__()\n",
    "        self.fc_1=nn.Linear(input_size,16)\n",
    "        self.fc_z_mean=nn.Linear(16,1)\n",
    "        self.fc_z_std=nn.Linear(16,1)\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "    def forward(self,z):\n",
    "        x=self.relu(self.fc_1(z))\n",
    "        affine_1=self.fc_z_mean(x)\n",
    "        affine_2=torch.exp(self.fc_z_std(x))\n",
    "        return affine_1,affine_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26a5ef30-a3f0-4b11-9581-72a13d9ce4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self, z_dim=512):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(z_dim,k=32)\n",
    "        self.encoder.apply(init_weights)\n",
    "        self.decoder = Decoder(z_dim,k=32)\n",
    "        self.decoder.apply(init_weights)\n",
    "\n",
    "        #self.prior_net.train()\n",
    "        #self.generation_net.train()\n",
    "        self.z_dim=z_dim\n",
    "        #self.recognition_net = Encoder(z_dim,k=4)\n",
    "        self.age_nn=MLP(input_size=1,z_dim=4)\n",
    "        #self.age_flow_components = ConditionalAffineTransform(context_nn=age_nn, event_dim=0)\n",
    "        #self.age_flow_transforms = [self.age_flow_components]\n",
    "        self.age_estimator=Estimator(input_size=512,z_dim=1)\n",
    "    #@pyro_method\n",
    "    #def pgm_model(self):\n",
    "\n",
    "        #return {'age': age_base_dist}\n",
    "        \n",
    "    def model(self, xs,age=None):\n",
    "            # register this pytorch module and all of its sub-modules with pyro\n",
    "            \n",
    "            pyro.module(\"decoder\",self.decoder)\n",
    "            with pyro.plate(\"data\",xs.shape[0]):\n",
    "                \n",
    "                #obs=pgm_model()\n",
    "                age_mean=xs.new_ones(torch.Size((xs.shape[0], 1)))*60.8\n",
    "                age_base_scale=xs.new_ones(torch.Size((xs.shape[0], 1)))*12.89\n",
    "                age_dist = dist.Normal(age_mean, age_base_scale).to_event(1)\n",
    "                age = pyro.sample('age', age_dist)\n",
    "                z_loc = xs.new_zeros(torch.Size((xs.shape[0], self.z_dim)))\n",
    "                z_scale = z_scale = xs.new_ones(torch.Size((xs.shape[0], self.z_dim)))\n",
    "                z_base_dist = dist.Normal(z_loc, z_scale)\n",
    "                z = pyro.sample('latent',z_base_dist.to_event(1))\n",
    "                ctx=torch.cat([z,age,age,age,age],-1)  \n",
    "                #ctx=torch.cat([z],-1)  \n",
    "                \n",
    "                #RelaxedBernoulliStraightThrough\n",
    "                #z_probs_1=xs.new_ones(torch.Size((xs.shape[0], 16, 32, 32)))*.5                \n",
    "                #z_dist_1 = pyro.sample(\"z_1\",RelaxedBernoulliStraightThrough(torch.Tensor([2./3]).cuda(),probs=z_probs_1).to_event(3))\n",
    "                #z_probs_2=xs.new_ones(torch.Size((xs.shape[0], 16, 16, 16)))*.5                \n",
    "                #z_dist_2 = pyro.sample(\"z_2\",RelaxedBernoulliStraightThrough(torch.Tensor([2./3]).cuda(),probs=z_probs_2).to_event(3))\n",
    "                \n",
    "                loc,var = self.decoder(ctx)\n",
    "                var=xs.new_ones(torch.Size(loc.shape))*.5\n",
    "                #print(var)\n",
    "                #print(loc.shape)\n",
    "                pyro.sample('obs', dist.Normal(loc.unsqueeze(1),var.unsqueeze(1)).to_event(3), obs=xs)\n",
    "                #return loc\n",
    "    def guide(self, xs,age=None):\n",
    "            pyro.module(\"encoder\",self.encoder)\n",
    "            with pyro.plate(\"data\",xs.shape[0]):\n",
    "                z_loc, z_scale,z_1,z_2 = self.encoder(xs)\n",
    "                pyro.sample('latent', dist.Normal(z_loc, z_scale).to_event(1))\n",
    "                age_loc,age_scale=self.age_estimator(z_loc)\n",
    "                pyro.sample('age', dist.Normal(age_loc,age_scale).to_event(1))\n",
    "                #pyro.sample(\"z_1\",RelaxedBernoulliStraightThrough(torch.Tensor([2./3]).cuda(),probs=z_1).to_event(3))\n",
    "                #pyro.sample(\"z_2\",RelaxedBernoulliStraightThrough(torch.Tensor([2./3]).cuda(),probs=z_2).to_event(3))\n",
    "\n",
    "    def reconstruct(self,xs,age):\n",
    "        z_loc, z_scale = self.encoder(xs)\n",
    "        print(z_loc)\n",
    "        # sample in latent space\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        ctx=torch.cat([z,age],-1)\n",
    "        # decode the image (note we don't sample in image space)\n",
    "        loc,var=self.decoder(ctx)\n",
    "        return loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9c5638c-29db-48cf-97ba-4e8ea1d05d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.cuda.current_device()\n",
    "pyro.clear_param_store()\n",
    "my_VAE=CVAE()\n",
    "my_VAE.to(device)\n",
    "#optimizer = pyro.optim.Adam({\"lr\": learning_rate})\n",
    "optimizer = pyro.optim.Adam({\"lr\": .001})\n",
    "svi = SVI(my_VAE.model, my_VAE.guide, optimizer, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c270a875-df53-4be1-ad6e-32c586b08573",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= build_dataset(root_dir='/usr/local/faststorage/BraTS19_Data/',dataset_type=\"train\",mode=MODALS[\"T1\"])\n",
    "train_loader=VolumeLoader(dataset=train_dataset,root_dir='/usr/local/faststorage/BraTS19_Data/',dataset_type=\"train\",mode=MODALS[\"T1\"])\n",
    "train_pydl=torch.utils.data.DataLoader(train_loader,batch_size=64,num_workers=16,shuffle=False)\n",
    "\n",
    "val_dataset= build_dataset(root_dir='/usr/local/faststorage/BraTS19_Data/',dataset_type=\"val\",mode=MODALS[\"T1\"])\n",
    "val_loader=VolumeLoader(dataset=val_dataset,root_dir='/usr/local/faststorage/BraTS19_Data/',dataset_type=\"val\",mode=MODALS[\"T1\"])\n",
    "val_pydl=torch.utils.data.DataLoader(val_loader,batch_size=4,num_workers=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7ee5cd8-873d-4b1f-9061-ef46186d99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(pydl):\n",
    "    loss=0.\n",
    "    for i,data in enumerate(train_pydl):\n",
    "        \n",
    "        img=data[\"MRI\"]\n",
    "        img=img[:,50:178:2,178//2,12:140:2]\n",
    "        img=img-torch.mean(img,axis=(1,2),keepdims=True)\n",
    "        img=img/torch.std(img,axis=(1,2),keepdims=True)\n",
    "        img=img.unsqueeze(1).type(torch.FloatTensor)\n",
    "        #for i in range(100):\n",
    "        loss+=svi.step(xs=img.cuda(),age=data[\"Age\"].type(torch.FloatTensor).view(-1,1).cuda())\n",
    "        #break\n",
    "    return loss\n",
    "def precompute(pydl):\n",
    "    loss=0.\n",
    "    ages=[]\n",
    "    for i,data in enumerate(train_pydl):\n",
    "        ages.append(data[\"Age\"].numpy())\n",
    "    print(np.mean(np.asarray(ages)))\n",
    "    print(np.std(np.asarray(ages)))\n",
    "                    \n",
    "def evaluate(pydl):\n",
    "    loss=0.\n",
    "    for i,data in enumerate(train_pydl):\n",
    "        img=data[\"MRI\"]\n",
    "        #img=img[:,50:178:2,50:178:2,63]\n",
    "        img=img[:,50:178:2,178//2,12:140:2]\n",
    "        img=img-torch.mean(img,axis=(1,2),keepdims=True)\n",
    "        img=img/torch.std(img,axis=(1,2),keepdims=True)\n",
    "        img=img.unsqueeze(1).type(torch.FloatTensor)\n",
    "        loss = svi.evaluate_loss(xs=img.cuda(), age=data[\"Age\"].type(torch.FloatTensor).view(-1,1).cuda())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42766a2-7c88-463e-847c-74311f5aeca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Training loss is:2224904.285118103\n",
      "Validation loss is:231997.837890625\n",
      "2224904.285118103\n",
      "epoch 1\n",
      "Training loss is:997141.515548706\n",
      "Validation loss is:174713.486328125\n",
      "997141.515548706\n",
      "epoch 2\n",
      "Training loss is:808052.2674827576\n",
      "Validation loss is:152759.689453125\n",
      "808052.2674827576\n",
      "epoch 3\n",
      "Training loss is:729469.0081939697\n",
      "Validation loss is:144294.765625\n",
      "729469.0081939697\n",
      "epoch 4\n",
      "Training loss is:683211.2449493408\n",
      "Validation loss is:136620.27734375\n",
      "683211.2449493408\n",
      "epoch 5\n",
      "Training loss is:646834.0202636719\n",
      "Validation loss is:131038.072265625\n",
      "646834.0202636719\n",
      "epoch 6\n",
      "Training loss is:627339.1242752075\n",
      "Validation loss is:127018.220703125\n",
      "627339.1242752075\n",
      "epoch 7\n",
      "Training loss is:611849.9588241577\n",
      "Validation loss is:123699.140625\n",
      "611849.9588241577\n",
      "epoch 8\n",
      "Training loss is:598926.4289550781\n",
      "Validation loss is:121029.39453125\n",
      "598926.4289550781\n",
      "epoch 9\n",
      "Training loss is:590254.6182785034\n",
      "Validation loss is:120107.056640625\n",
      "590254.6182785034\n",
      "epoch 10\n",
      "Training loss is:582540.6107635498\n",
      "Validation loss is:117339.92578125\n",
      "582540.6107635498\n",
      "epoch 11\n",
      "Training loss is:573769.589515686\n",
      "Validation loss is:116567.861328125\n",
      "573769.589515686\n",
      "epoch 12\n",
      "Training loss is:560971.4917144775\n",
      "Validation loss is:114217.9609375\n",
      "560971.4917144775\n",
      "epoch 13\n",
      "Training loss is:553849.2662658691\n",
      "Validation loss is:111774.845703125\n",
      "553849.2662658691\n",
      "epoch 14\n",
      "Training loss is:548971.7742118835\n",
      "Validation loss is:110578.431640625\n",
      "548971.7742118835\n",
      "epoch 15\n",
      "Training loss is:542590.5870895386\n",
      "Validation loss is:109738.6875\n",
      "542590.5870895386\n",
      "epoch 16\n",
      "Training loss is:536043.2887573242\n",
      "Validation loss is:108732.7265625\n",
      "536043.2887573242\n",
      "epoch 17\n",
      "Training loss is:531997.3853912354\n",
      "Validation loss is:108676.63671875\n",
      "531997.3853912354\n",
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fa81af5e4e0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/faststorage/jddursof/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/faststorage/jddursof/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fa962e66c88>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/faststorage/jddursof/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/faststorage/jddursof/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 230, in _feed\n",
      "    close()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 230, in _feed\n",
      "    close()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 230, in _feed\n",
      "    close()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss is:528578.7179489136\n",
      "Validation loss is:106036.5625\n",
      "528578.7179489136\n",
      "epoch 19\n",
      "Training loss is:522385.7642250061\n",
      "Validation loss is:106264.59765625\n",
      "522385.7642250061\n",
      "epoch 20\n",
      "Training loss is:516086.4274902344\n",
      "Validation loss is:104329.30859375\n",
      "516086.4274902344\n",
      "epoch 21\n",
      "Training loss is:512368.4981918335\n",
      "Validation loss is:103507.935546875\n",
      "512368.4981918335\n",
      "epoch 22\n",
      "Training loss is:508244.1377105713\n",
      "Validation loss is:102919.4375\n",
      "508244.1377105713\n",
      "epoch 23\n",
      "Training loss is:506996.5707092285\n",
      "Validation loss is:103590.423828125\n",
      "506996.5707092285\n",
      "epoch 24\n",
      "Training loss is:507461.60134124756\n",
      "Validation loss is:101580.302734375\n",
      "epoch 25\n",
      "Training loss is:501817.6791038513\n",
      "Validation loss is:100329.34765625\n",
      "501817.6791038513\n",
      "epoch 26\n",
      "Training loss is:497150.46242523193\n",
      "Validation loss is:101375.798828125\n",
      "497150.46242523193\n",
      "epoch 27\n",
      "Training loss is:493675.8851699829\n",
      "Validation loss is:99917.796875\n",
      "493675.8851699829\n",
      "epoch 28\n",
      "Training loss is:489990.2418899536\n",
      "Validation loss is:99096.970703125\n",
      "489990.2418899536\n",
      "epoch 29\n",
      "Training loss is:486696.31579589844\n",
      "Validation loss is:98330.892578125\n",
      "486696.31579589844\n",
      "epoch 30\n",
      "Training loss is:483897.7201385498\n",
      "Validation loss is:96998.3671875\n",
      "483897.7201385498\n",
      "epoch 31\n",
      "Training loss is:482614.40690612793\n",
      "Validation loss is:96392.125\n",
      "482614.40690612793\n",
      "epoch 32\n",
      "Training loss is:480992.8253250122\n",
      "Validation loss is:96385.337890625\n",
      "480992.8253250122\n",
      "epoch 33\n",
      "Training loss is:478322.20237350464\n",
      "Validation loss is:96774.228515625\n",
      "478322.20237350464\n",
      "epoch 34\n",
      "Training loss is:477136.7805252075\n",
      "Validation loss is:96040.216796875\n",
      "477136.7805252075\n",
      "epoch 35\n",
      "Training loss is:475683.47831344604\n",
      "Validation loss is:95634.46484375\n",
      "475683.47831344604\n",
      "epoch 36\n",
      "Training loss is:472502.5613479614\n",
      "Validation loss is:94601.064453125\n",
      "472502.5613479614\n",
      "epoch 37\n",
      "Training loss is:469867.31717681885\n",
      "Validation loss is:95272.2421875\n",
      "469867.31717681885\n",
      "epoch 38\n",
      "Training loss is:468841.57750701904\n",
      "Validation loss is:95600.943359375\n",
      "468841.57750701904\n",
      "epoch 39\n",
      "Training loss is:467460.95695114136\n",
      "Validation loss is:94290.64453125\n",
      "467460.95695114136\n",
      "epoch 40\n",
      "Training loss is:465873.4247665405\n",
      "Validation loss is:93749.810546875\n",
      "465873.4247665405\n",
      "epoch 41\n",
      "Training loss is:465060.0721054077\n",
      "Validation loss is:93318.7109375\n",
      "465060.0721054077\n",
      "epoch 42\n",
      "Training loss is:462842.2613220215\n",
      "Validation loss is:92976.455078125\n",
      "462842.2613220215\n",
      "epoch 43\n",
      "Training loss is:462906.73070144653\n",
      "Validation loss is:92784.294921875\n",
      "epoch 44\n",
      "Training loss is:460003.7104110718\n",
      "Validation loss is:93242.9375\n",
      "460003.7104110718\n",
      "epoch 45\n",
      "Training loss is:460445.8988189697\n",
      "Validation loss is:92509.02734375\n",
      "epoch 46\n",
      "Training loss is:459321.7552947998\n",
      "Validation loss is:91753.99609375\n",
      "459321.7552947998\n",
      "epoch 47\n",
      "Training loss is:455891.31147766113\n",
      "Validation loss is:92010.48046875\n",
      "455891.31147766113\n",
      "epoch 48\n",
      "Training loss is:454839.6635437012\n",
      "Validation loss is:91883.263671875\n",
      "454839.6635437012\n",
      "epoch 49\n",
      "Training loss is:453513.33950805664\n",
      "Validation loss is:91377.296875\n",
      "453513.33950805664\n",
      "epoch 50\n",
      "Training loss is:451049.0066833496\n",
      "Validation loss is:91516.435546875\n",
      "451049.0066833496\n",
      "epoch 51\n",
      "Training loss is:450336.8890686035\n",
      "Validation loss is:90625.666015625\n",
      "450336.8890686035\n",
      "epoch 52\n",
      "Training loss is:450128.45703125\n",
      "Validation loss is:90663.1796875\n",
      "450128.45703125\n",
      "epoch 53\n",
      "Training loss is:449209.07821655273\n",
      "Validation loss is:90703.93359375\n",
      "449209.07821655273\n",
      "epoch 54\n",
      "Training loss is:448198.3119506836\n",
      "Validation loss is:90198.068359375\n",
      "448198.3119506836\n",
      "epoch 55\n",
      "Training loss is:445234.43335723877\n",
      "Validation loss is:89570.208984375\n",
      "445234.43335723877\n",
      "epoch 56\n",
      "Training loss is:444884.8143386841\n",
      "Validation loss is:89275.974609375\n",
      "444884.8143386841\n",
      "epoch 57\n",
      "Training loss is:444834.16956329346\n",
      "Validation loss is:89241.306640625\n",
      "444834.16956329346\n",
      "epoch 58\n",
      "Training loss is:442446.9914550781\n",
      "Validation loss is:89565.876953125\n",
      "442446.9914550781\n",
      "epoch 59\n",
      "Training loss is:442588.3045806885\n",
      "Validation loss is:89563.05078125\n",
      "epoch 60\n",
      "Training loss is:443554.2029495239\n",
      "Validation loss is:88564.158203125\n",
      "epoch 61\n",
      "Training loss is:442320.5774612427\n",
      "Validation loss is:88317.07421875\n",
      "442320.5774612427\n",
      "epoch 62\n",
      "Training loss is:440872.0782623291\n",
      "Validation loss is:88371.73046875\n",
      "440872.0782623291\n",
      "epoch 63\n",
      "Training loss is:440040.8917388916\n",
      "Validation loss is:87983.181640625\n",
      "440040.8917388916\n",
      "epoch 64\n",
      "Training loss is:438105.4913864136\n",
      "Validation loss is:88075.927734375\n",
      "438105.4913864136\n",
      "epoch 65\n",
      "Training loss is:437306.6042022705\n",
      "Validation loss is:88308.27734375\n",
      "437306.6042022705\n",
      "epoch 66\n",
      "Training loss is:434784.9962539673\n",
      "Validation loss is:87190.47265625\n",
      "434784.9962539673\n",
      "epoch 67\n",
      "Training loss is:432257.44202423096\n",
      "Validation loss is:87039.255859375\n",
      "432257.44202423096\n",
      "epoch 68\n",
      "Training loss is:432443.190284729\n",
      "Validation loss is:86699.42578125\n",
      "epoch 69\n",
      "Training loss is:430122.40660858154\n",
      "Validation loss is:87121.982421875\n",
      "430122.40660858154\n",
      "epoch 70\n",
      "Training loss is:428193.02672576904\n",
      "Validation loss is:86153.916015625\n",
      "428193.02672576904\n",
      "epoch 71\n",
      "Training loss is:429183.93775177\n",
      "Validation loss is:86433.681640625\n",
      "epoch 72\n",
      "Training loss is:427876.82012939453\n",
      "Validation loss is:85855.953125\n",
      "427876.82012939453\n",
      "epoch 73\n",
      "Training loss is:427922.47721481323\n",
      "Validation loss is:86164.19921875\n",
      "epoch 74\n",
      "Training loss is:426607.2355194092\n",
      "Validation loss is:85406.279296875\n",
      "426607.2355194092\n",
      "epoch 75\n",
      "Training loss is:426205.052482605\n",
      "Validation loss is:85586.61328125\n",
      "426205.052482605\n",
      "epoch 76\n",
      "Training loss is:423540.98069763184\n",
      "Validation loss is:85377.822265625\n",
      "423540.98069763184\n",
      "epoch 77\n",
      "Training loss is:424152.1809387207\n",
      "Validation loss is:85688.677734375\n",
      "epoch 78\n",
      "Training loss is:423879.18072509766\n",
      "Validation loss is:84781.46875\n",
      "epoch 79\n",
      "Training loss is:420989.63359069824\n",
      "Validation loss is:84912.09765625\n",
      "420989.63359069824\n",
      "epoch 80\n",
      "Training loss is:421604.6238632202\n",
      "Validation loss is:85185.38671875\n",
      "epoch 81\n",
      "Training loss is:420192.84690093994\n",
      "Validation loss is:84201.177734375\n",
      "420192.84690093994\n",
      "epoch 82\n",
      "Training loss is:417741.80153656006\n",
      "Validation loss is:84088.021484375\n",
      "417741.80153656006\n",
      "epoch 83\n",
      "Training loss is:418832.026927948\n",
      "Validation loss is:84179.359375\n",
      "epoch 84\n",
      "Training loss is:418175.65409088135\n",
      "Validation loss is:84059.828125\n",
      "epoch 85\n",
      "Training loss is:416406.9317512512\n",
      "Validation loss is:84095.900390625\n",
      "416406.9317512512\n",
      "epoch 86\n",
      "Training loss is:416584.4758300781\n",
      "Validation loss is:83497.43359375\n",
      "epoch 87\n",
      "Training loss is:415327.6739730835\n",
      "Validation loss is:83974.15625\n",
      "415327.6739730835\n",
      "epoch 88\n",
      "Training loss is:415152.1845321655\n",
      "Validation loss is:83487.166015625\n",
      "415152.1845321655\n",
      "epoch 89\n",
      "Training loss is:415888.63092803955\n",
      "Validation loss is:83686.611328125\n",
      "epoch 90\n",
      "Training loss is:415955.77074432373\n",
      "Validation loss is:84179.7109375\n",
      "epoch 91\n",
      "Training loss is:417392.1870651245\n",
      "Validation loss is:82914.74609375\n",
      "epoch 92\n",
      "Training loss is:414495.5841598511\n",
      "Validation loss is:83540.259765625\n",
      "414495.5841598511\n",
      "epoch 93\n",
      "Training loss is:412483.75161743164\n",
      "Validation loss is:83089.3046875\n",
      "412483.75161743164\n",
      "epoch 94\n",
      "Training loss is:411935.7287750244\n",
      "Validation loss is:82972.8125\n",
      "411935.7287750244\n",
      "epoch 95\n",
      "Training loss is:410442.32456207275\n",
      "Validation loss is:82877.875\n",
      "410442.32456207275\n",
      "epoch 96\n",
      "Training loss is:409208.8920135498\n",
      "Validation loss is:81972.509765625\n",
      "409208.8920135498\n",
      "epoch 97\n",
      "Training loss is:408136.3168182373\n",
      "Validation loss is:82224.6875\n",
      "408136.3168182373\n",
      "epoch 98\n",
      "Training loss is:408823.388923645\n",
      "Validation loss is:82152.2890625\n",
      "epoch 99\n",
      "Training loss is:408288.3400039673\n",
      "Validation loss is:82325.455078125\n",
      "epoch 100\n",
      "Training loss is:408012.4183502197\n",
      "Validation loss is:82141.171875\n",
      "408012.4183502197\n",
      "epoch 101\n",
      "Training loss is:406531.6913986206\n",
      "Validation loss is:82355.236328125\n",
      "406531.6913986206\n",
      "epoch 102\n",
      "Training loss is:407341.1960144043\n",
      "Validation loss is:82083.0078125\n",
      "epoch 103\n",
      "Training loss is:407058.9028625488\n",
      "Validation loss is:81946.900390625\n",
      "epoch 104\n",
      "Training loss is:406387.9821166992\n",
      "Validation loss is:81846.9296875\n",
      "406387.9821166992\n",
      "epoch 105\n",
      "Training loss is:405546.75717163086\n",
      "Validation loss is:81753.76953125\n",
      "405546.75717163086\n",
      "epoch 106\n",
      "Training loss is:407457.45024108887\n",
      "Validation loss is:81872.0390625\n",
      "epoch 107\n",
      "Training loss is:405880.7083129883\n",
      "Validation loss is:81410.33203125\n",
      "epoch 108\n",
      "Training loss is:402805.02241897583\n",
      "Validation loss is:81291.376953125\n",
      "402805.02241897583\n",
      "epoch 109\n",
      "Training loss is:401124.55656433105\n",
      "Validation loss is:81175.3671875\n",
      "401124.55656433105\n",
      "epoch 110\n",
      "Training loss is:401393.4934310913\n",
      "Validation loss is:80444.064453125\n",
      "epoch 111\n",
      "Training loss is:399935.8823776245\n",
      "Validation loss is:80972.61328125\n",
      "399935.8823776245\n",
      "epoch 112\n",
      "Training loss is:400606.5517272949\n",
      "Validation loss is:80843.720703125\n",
      "epoch 113\n",
      "Training loss is:399851.9087753296\n",
      "Validation loss is:80317.87890625\n",
      "399851.9087753296\n",
      "epoch 114\n",
      "Training loss is:398719.9737548828\n",
      "Validation loss is:80082.48046875\n",
      "398719.9737548828\n",
      "epoch 115\n",
      "Training loss is:396674.5464935303\n",
      "Validation loss is:80653.744140625\n",
      "396674.5464935303\n",
      "epoch 116\n",
      "Training loss is:396166.08547210693\n",
      "Validation loss is:79476.484375\n",
      "396166.08547210693\n",
      "epoch 117\n",
      "Training loss is:396269.44857025146\n",
      "Validation loss is:79451.81640625\n",
      "epoch 118\n",
      "Training loss is:395777.95067596436\n",
      "Validation loss is:79383.974609375\n",
      "395777.95067596436\n",
      "epoch 119\n"
     ]
    }
   ],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]\n",
    "val_loss_best=np.inf\n",
    "#precompute(train_pydl)\n",
    "#my_VAE=torch.load(\"./training/best_model\")\n",
    "for i in range(1000):\n",
    "    print(\"epoch \" +str(i))\n",
    "    train_loss.append(train(train_pydl))\n",
    "    print(\"Training loss is:\" +str(train_loss[-1]))\n",
    "    val_loss.append(evaluate(val_pydl))\n",
    "    print(\"Validation loss is:\" +str(val_loss[-1]))\n",
    "    if train_loss[-1]<val_loss_best:\n",
    "        val_loss_best=train_loss[-1]\n",
    "        print(val_loss_best)\n",
    "        torch.save(my_VAE, \"./best_model_sag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc63463-b18b-46d3-b41f-d22e76a03e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cea5ce-f6da-4dda-9443-9ecea60bafc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(my_VAE.reconstruct(torch.Tensor(resha_slice),age=torch.Tensor([[50]]).view(1,1)).detach().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce574474-4db4-4c7e-9a89-f2eff76e93e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5d8a52-fac9-46a5-a68b-964c5be483e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cfb585-ed0f-4e48-9bf5-57ae7d9a1b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497bf9b0-64d6-496a-a767-f2d35b192aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5babd3-81e4-4e02-a0df-df4755e96229",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee962a-8abb-4544-8694-a661f57a9eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b600e27-9512-4681-b529-7308981df766",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea4103-2a5a-4bfe-9c78-05bc045c2587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ccba09-9379-495d-940d-f969936010c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0525d00b-f71d-4879-8247-be18f4d956e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
